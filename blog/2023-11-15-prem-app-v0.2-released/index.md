---
slug: prem-app-v0-2-enhanced-speed-without-docker
title: "Introducing Prem App v0.2.x: Enhanced Speed and Simplified Usage Without Docker"
authors: [tiero]
tags: [llm, ai, self-hosted, prem, on-premise, open-source, mistral, whisper, tabby]
description: "Discover the new Prem App v0.2: Enhanced for Mac with Apple Silicon. Experience faster AI inference without Docker. Now featuring models like Mistral Instruct 7B, Whisper Tiny, MiniLM L6 v2, and more. Ideal for developers and AI enthusiasts seeking advanced AI capabilities on Mac OS. Upgrade your AI tools with Prem App's latest version"
image: "./image.png"
---
<!--truncate-->

<head>
  <meta name="twitter:image" content="./image.png"/>
</head>

We are excited to announce the release of Prem App v0.2.x. This update brings groundbreaking improvements and features, enhancing your private and sovereign generative AI experience on Mac OS with Apple Silicon chip.

![Prem Desktop App with model gallery](./image.png)

ðŸ‘‰ **[Dowload the latest Prem Desktop App now for MacOS with Apple chip](https://install-app.prem.ninja/latest-release)**

Here's what you can expect:

### No More Docker Dependency
We've listened to your feedback and removed the need for Docker. This means a simpler, more streamlined setup process for all users.

### Rust-Powered Binary Controller
Our new Rust binary controller efficiently manages the lifecycle of AI models running locally. It handles everything from downloading to running, stopping, and deleting AI model binaries from the user interface.

### Optimized for Apple Silicon
Prem App v0.2 fully leverages the power of Apple Silicon GPUs. This optimization allows for running larger AI models, resulting in quicker and higher-quality outputs.

### A Diverse Range of AI Models
We're proud to offer a wide range of AI models to cater to various needs and applications. With Prem App v0.2, you have access to:

- [**Mistral Instruct 7B**](https://registry.premai.io/detail.html?service=mistral-7b-instruct): A versatile model for a range of instructive tasks.
- [**Mistral 7B with 128k Context**](https://registry.premai.io/detail.html?service=mistral-7b-128k): Ideal for handling extensive context requirements.
- [**Whisper Tiny**](https://registry.premai.io/detail.html?service=whisper-tiny-cpp): A compact yet powerful model for speech-to-text needs.
- [**All MiniLM L6 v2**](https://registry.premai.io/detail.html?service=all-minilm-l6-v2): Perfect for generating embeddings with high accuracy.
- [**Qdrant**](https://registry.premai.io/detail.html?service=qdrant): A robust vector store database for your data management needs.
- [**Tabby StarCoder 1B**](https://registry.premai.io/detail.html?service=tabby-starcoder-1b): Tailored for coding and programming-related tasks.
- [**Tabby CodeLLama 7B**](https://registry.premai.io/detail.html?service=tabby-codellama-7B): Another excellent option for developers and programmers.

These models represent the cutting edge in open-source generative AI, ensuring you have the tools you need for a wide range of applications.

### Conclusion
Prem App v0.2 is more than an update; it's a leap forward local inference on Mac OS, especially for Apple Silicon users. It's about giving you faster, more efficient, and high-quality AI capabilities without the complexity. We're excited for you to experience these advancements and look forward to your feedback.

Thank you for your continued support, and stay tuned for more updates!

